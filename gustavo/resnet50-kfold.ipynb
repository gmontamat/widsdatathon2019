{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet based model with augmentation and K-fold cross validation\n",
    "\n",
    "## Import modules and load data from pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), '..', 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 256\n",
    "width = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load both the original and the augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'train_images_256x256.pkl'), 'rb') as fin:\n",
    "    train_images = pickle.load(fin)\n",
    "with open(os.path.join(data_path, 'train_responses.pkl'), 'rb') as fin:\n",
    "    train_responses = pickle.load(fin)\n",
    "with open(os.path.join(data_path, 'train_scores.pkl'), 'rb') as fin:\n",
    "    train_scores = pickle.load(fin)\n",
    "with open(os.path.join(data_path, 'augmented_images_256x256.pkl'), 'rb') as fin:\n",
    "    augmented_images = pickle.load(fin)\n",
    "with open(os.path.join(data_path, 'augmented_responses.pkl'), 'rb') as fin:\n",
    "    augmented_responses = pickle.load(fin)\n",
    "with open(os.path.join(data_path, 'augmented_scores.pkl'), 'rb') as fin:\n",
    "    augmented_scores = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the data by their score to create representative folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_90 = train_images[train_scores.squeeze() > .9, :, :, :]\n",
    "train_responses_90 = train_responses[train_scores.squeeze() > .9, :]\n",
    "train_images_70 = train_images[(train_scores.squeeze() < .9) & (train_scores.squeeze() > .7), :, :, :]\n",
    "train_responses_70 = train_responses[(train_scores.squeeze() < .9) & (train_scores.squeeze() > .7), :]\n",
    "train_images_50 = train_images[train_scores.squeeze() < .7, :, :, :]\n",
    "train_responses_50 = train_responses[train_scores.squeeze() < .7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_images\n",
    "del train_responses\n",
    "del train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images_90 = augmented_images[augmented_scores.squeeze() > .9, :, :, :]\n",
    "augmented_responses_90 = augmented_responses[augmented_scores.squeeze() > .9, :]\n",
    "augmented_images_70 = augmented_images[(augmented_scores.squeeze() < .9) & (augmented_scores.squeeze() > .7), :, :, :]\n",
    "augmented_responses_70 = augmented_responses[(augmented_scores.squeeze() < .9) & (augmented_scores.squeeze() > .7), :]\n",
    "augmented_images_50 = augmented_images[augmented_scores.squeeze() < .7, :, :, :]\n",
    "augmented_responses_50 = augmented_responses[augmented_scores.squeeze() < .7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del augmented_images\n",
    "del augmented_responses\n",
    "del augmented_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images_90 = train_images_90 * 2. / 255. - 1.\n",
    "# train_images_70 = train_images_70 * 2. / 255. - 1.\n",
    "# train_images_50 = train_images_50 * 2. / 255. - 1.\n",
    "# augmented_images_90 = augmented_images_90 * 2. / 255. - 1.\n",
    "# augmented_images_70 = augmented_images_70 * 2. / 255. - 1.\n",
    "# augmented_images_50 = augmented_images_50 * 2. / 255. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_90 = preprocess_input(train_images_90)\n",
    "train_images_70 = preprocess_input(train_images_70)\n",
    "train_images_50 = preprocess_input(train_images_50)\n",
    "augmented_images_90 = preprocess_input(augmented_images_90)\n",
    "augmented_images_70 = preprocess_input(augmented_images_70)\n",
    "augmented_images_50 = preprocess_input(augmented_images_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocCallback(Callback):\n",
    "    \"\"\"\n",
    "    Define a callback which returns train ROC AUC after\n",
    "    each epoch and stops early when validation AUC\n",
    "    doesn't improve.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, training_data, validation_data, patience=5, baseline=0.999):\n",
    "        super(Callback, self).__init__()\n",
    "        self.best_roc_val = 0.\n",
    "        self.consecutive_worse = 0\n",
    "        self.patience = patience\n",
    "        self.baseline = baseline\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: {} - roc-auc-val: {}'.format(round(roc, 6), round(roc_val, 6)), end=80 * ' ' + '\\n')\n",
    "        if roc_val > self.best_roc_val:\n",
    "            self.consecutive_worse = 0\n",
    "            self.best_roc_val = roc_val\n",
    "            self.model.save_weights('best.h5')\n",
    "        else:\n",
    "            self.consecutive_worse += 1\n",
    "            if self.consecutive_worse >= self.patience:\n",
    "                if self.best_roc_val > self.baseline:\n",
    "                    print(\"Epoch {}: early stopping.\".format(epoch + 1))\n",
    "                    self.model.stop_training = True\n",
    "                    self.model.load_weights('best.h5')\n",
    "                else:\n",
    "                    print(\"Ran out of patience, resetting weights...\")\n",
    "                    self.model.load_weights('original.h5')\n",
    "                    self.best_roc_val = 0.\n",
    "                    self.consecutive_worse = 0\n",
    "                    # Relax baseline, model isn't complex enough\n",
    "                    if self.baseline > .997:\n",
    "                        self.baseline = self.baseline - .001\n",
    "                    elif epoch > 460:\n",
    "                        self.baseline = .996\n",
    "                    elif epoch > 400:\n",
    "                        # Relax even further\n",
    "                        self.baseline = .9965\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50():\n",
    "    resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(height, width, 3), pooling='avg')\n",
    "    last = resnet.output\n",
    "    # x = Flatten()(last)\n",
    "    # x = Dropout(0.5)(last)\n",
    "    # x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(last)\n",
    "    return Model(inputs=[resnet.input], outputs=[x])\n",
    "\n",
    "\n",
    "# model = resnet50()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folds and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for index_90, index_70, index_50 in zip(\n",
    "        skf.split(train_images_90, train_responses_90.squeeze()),\n",
    "        skf.split(train_images_70, train_responses_70.squeeze()),\n",
    "        skf.split(train_images_50, train_responses_50.squeeze())):\n",
    "    k += 1\n",
    "    train_index_90, test_index_90 = index_90\n",
    "    train_index_70, test_index_70 = index_70\n",
    "    train_index_50, test_index_50 = index_50\n",
    "    images = np.concatenate([\n",
    "        train_images_90[train_index_90, :, :, :],\n",
    "        train_images_70[train_index_70, :, :, :],\n",
    "        train_images_50[train_index_50, :, :, :]\n",
    "    ], axis=0)\n",
    "    responses = np.concatenate([\n",
    "        train_responses_90[train_index_90, :],\n",
    "        train_responses_70[train_index_70, :],\n",
    "        train_responses_50[train_index_50, :]\n",
    "    ], axis=0)\n",
    "    permutation = np.random.permutation(images.shape[0])\n",
    "    images = images[permutation, :, :, :]\n",
    "    responses = responses[permutation, :]\n",
    "    val_images = np.concatenate([\n",
    "        train_images_90[test_index_90, :, :, :],\n",
    "        train_images_70[test_index_70, :, :, :],\n",
    "        train_images_50[test_index_50, :, :, :]\n",
    "    ], axis=0)\n",
    "    val_responses = np.concatenate([\n",
    "        train_responses_90[test_index_90, :],\n",
    "        train_responses_70[test_index_70, :],\n",
    "        train_responses_50[test_index_50, :]\n",
    "    ], axis=0)\n",
    "    permutation = np.random.permutation(val_images.shape[0])\n",
    "    val_images = val_images[permutation, :, :, :]\n",
    "    val_responses = val_responses[permutation, :]\n",
    "    # Train model until validation ROC AUC can't be improved\n",
    "    model = resnet50()\n",
    "    model.save_weights('original.h5')\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=1e-4, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    model.fit(\n",
    "        images, responses, batch_size=16, epochs=500,\n",
    "        validation_data=(val_images, val_responses),\n",
    "        callbacks=[\n",
    "            RocCallback(training_data=(images, responses), validation_data=(val_images, val_responses))\n",
    "        ]\n",
    "    )\n",
    "    model.save('resnet50_kfold{}.h5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_as_array(image_id, size=None, image_set='train_images'):\n",
    "    image_path = os.path.join(data_path, image_set, image_id)\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if size is None:\n",
    "        return img\n",
    "    return cv2.resize(img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'leaderboard_test_data'\n",
    "holdout_dir = 'leaderboard_holdout_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_ids = []\n",
    "for image_id in os.listdir(os.path.join(data_path, test_dir)):\n",
    "    img = img_as_array(image_id, image_set=test_dir)\n",
    "    test_images.append(img.reshape(1, height, width, 3))\n",
    "    test_ids.append(image_id)\n",
    "for image_id in os.listdir(os.path.join(data_path, holdout_dir)):\n",
    "    img = img_as_array(image_id, image_set=holdout_dir)\n",
    "    test_images.append(img.reshape(1, height, width, 3))\n",
    "    test_ids.append(image_id)\n",
    "test_images = np.concatenate(test_images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images = test_images / 255.\n",
    "# test_images = test_images * 2. / 255. - 1.\n",
    "test_images = preprocess_input(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_predictions = []\n",
    "for i in range(1, kfold + 1):\n",
    "    model_name = 'resnet50_kfold{}.h5'.format(i)\n",
    "    model = load_model(model_name)\n",
    "    predictions = model.predict(test_images)\n",
    "    predictions = predictions.squeeze().tolist()\n",
    "    fold_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'has_oilpalm{}'.format(i + 1): fold_predictions[i] for i in range(kfold)}\n",
    "data_dict['image_id'] = test_ids\n",
    "submission = pd.DataFrame(data_dict).sort_values('image_id')\n",
    "submission['has_oilpalm'] = submission[['has_oilpalm{}'.format(i + 1) for i in range(kfold)]].mean(axis=1)\n",
    "submission = submission[['image_id', 'has_oilpalm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
